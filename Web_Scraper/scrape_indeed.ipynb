{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf2a7ae",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74ebb55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from itertools import cycle\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d9c80b",
   "metadata": {},
   "source": [
    "#### Get URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ab6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(position, location):\n",
    "    template = 'https://uk.indeed.com/jobs?q={}&l={}'\n",
    "    url = template.format(position, location)\n",
    "    return url\n",
    "\n",
    "url = get_url('software+consultant', 'london')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05198a21",
   "metadata": {},
   "source": [
    "#### Establish proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3570e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_params = {\n",
    "      'api_key': '78923aa5-caac-440a-a88f-d1105626fd12',\n",
    "      'url': url, \n",
    "      'render_js': True,\n",
    "  }\n",
    "\n",
    "response = requests.get(\n",
    "  url='https://proxy.scrapeops.io/v1/',\n",
    "  params=urlencode(proxy_params),\n",
    "  timeout=120,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e896119",
   "metadata": {},
   "source": [
    "#### Create BeautifulSoup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f639625",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb59c8",
   "metadata": {},
   "source": [
    "#### Create object for job listing cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3179ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards = soup.find_all('div', 'cardOutline')\n",
    "len(cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c4271",
   "metadata": {},
   "source": [
    "#### Prototype the model with a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b134ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose first card\n",
    "\n",
    "card = cards[0]\n",
    "\n",
    "# use dot notation to parse specific html content\n",
    "\n",
    "spantag = card.h2.a.span\n",
    "atag = card.h2.a\n",
    "\n",
    "# get data from the job card\n",
    "\n",
    "job_title = spantag.get('title')\n",
    "job_url = 'https://uk.indeed.com' + atag.get('href')\n",
    "company = card.find('span', 'companyName').text.strip()\n",
    "location = card.find('div', 'companyLocation').text.strip()\n",
    "summary = card.find('div', 'job-snippet').text.strip()\n",
    "summary = summary.replace('\\n', ' ')\n",
    "post_date = card.find('span', 'date').text\n",
    "post_date = post_date[6:]\n",
    "metadata = card.find('div', 'attribute_snippet').text\n",
    "today = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903efbe",
   "metadata": {},
   "source": [
    "#### define function that gets records from each card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "545aedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(card):\n",
    "    spantag = card.h2.a.span\n",
    "    atag = card.h2.a\n",
    "    job_title = spantag.get('title')\n",
    "    job_url = 'https://uk.indeed.com' + atag.get('href')\n",
    "    company = card.find('span', 'companyName').text.strip()\n",
    "    location = card.find('div', 'companyLocation').text.strip()\n",
    "    summary = card.find('div', 'job-snippet').text.strip()\n",
    "    summary = summary.replace('\\n', ' ')\n",
    "    post_date = card.find('span', 'date').text.strip()\n",
    "    post_date = post_date[6:]\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    try:\n",
    "        metadata = card.find('div', 'attribute_snippet').text.strip()\n",
    "    except AttributeError:\n",
    "        metadata = ''\n",
    "    \n",
    "    record = (job_title, company, location, metadata, post_date, today, summary, job_url)\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ba564",
   "metadata": {},
   "source": [
    "#### Loop through cards and store data in empty list called records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5077928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for card in cards:\n",
    "    record = get_record(card)\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23acfbc3",
   "metadata": {},
   "source": [
    "#### Getting next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7327fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        url = 'https://uk.indeed.com' + soup.find('a', {'aria-label': 'Next Page'}).get('href')\n",
    "    except AttributeError:\n",
    "        break\n",
    "        \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    cards = soup.find_all('div', 'cardOutline')\n",
    "    \n",
    "    for card in cards:\n",
    "        record = get_record(card)\n",
    "        records.append(record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a4fa18",
   "metadata": {},
   "source": [
    "#### Final Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b8e28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from itertools import cycle\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "def get_url(position, location):\n",
    "    template = 'https://uk.indeed.com/jobs?q={}&l={}'\n",
    "    url = template.format(position, location)\n",
    "    return url\n",
    "\n",
    "def get_record(card):\n",
    "    spantag = card.h2.a.span\n",
    "    atag = card.h2.a\n",
    "    job_title = spantag.get('title')\n",
    "    job_url = 'https://uk.indeed.com' + atag.get('href')\n",
    "    company = card.find('span', 'companyName').text.strip()\n",
    "    location = card.find('div', 'companyLocation').text.strip()\n",
    "    summary = card.find('div', 'job-snippet').text.strip()\n",
    "    summary = summary.replace('\\n', ' ')\n",
    "    post_date = card.find('span', 'date').text.strip()\n",
    "    post_date = post_date[6:]\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    try:\n",
    "        metadata = card.find('div', 'attribute_snippet').text.strip()\n",
    "    except AttributeError:\n",
    "        metadata = ''\n",
    "    \n",
    "    record = (job_title, company, location, metadata, post_date, today, summary, job_url)\n",
    "    \n",
    "    return record\n",
    "\n",
    "def main(position, location):\n",
    "    records = []\n",
    "    url = get_url(position, location)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        proxy_params = {\n",
    "        'api_key': '78923aa5-caac-440a-a88f-d1105626fd12',\n",
    "        'url': url, \n",
    "        'render_js': True,}\n",
    "        response = requests.get(\n",
    "        url='https://proxy.scrapeops.io/v1/',\n",
    "        params=urlencode(proxy_params),\n",
    "        timeout=120,)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        cards = soup.find_all('div', 'cardOutline')  \n",
    "    \n",
    "        for card in cards:\n",
    "            record = get_record(card)\n",
    "            records.append(record)\n",
    "        \n",
    "        try:\n",
    "            url = 'https://uk.indeed.com' + soup.find('a', {'aria-label': 'Next Page'}).get('href')\n",
    "        except AttributeError:\n",
    "            break\n",
    "        \n",
    "    \n",
    "        for card in cards:\n",
    "            record = get_record(card)\n",
    "            records.append(record)\n",
    "            \n",
    "    with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Job Title', 'Company Name', 'Location', 'Metadata', 'Post Date', 'Today', 'Job Description', 'URL'])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54914464",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('software+consultant', 'bournemouth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c66e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
